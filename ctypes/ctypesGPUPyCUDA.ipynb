{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axXhTteb-MJe",
        "outputId": "e88513f2-8d42-4e04-ecc7-ad5ae5fa48c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycuda in /usr/local/lib/python3.10/dist-packages (2022.2.2)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.10/dist-packages (from pycuda) (2023.1.1)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (1.4.4)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.10/dist-packages (from pycuda) (1.2.4)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (3.11.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (2.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile sumArrayGPU.cu\n",
        "// CUDA kernel function\n",
        "\n",
        "extern \"C\" __global__ void my_cuda_kernel(int *input, int *output, int size) {\n",
        "    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if (tid < size) {\n",
        "        output[tid] = input[tid] * 2;  // Example: Double each element\n",
        "    }\n",
        "}\n",
        "\n",
        "// Wrapper function to call the CUDA kernel\n",
        "extern \"C\" void my_cuda_function(int *input, int *output, int size) {\n",
        "    // No need for memory allocations or movements here.\n",
        "    // These will be handled by PyCUDA in the Python code.\n",
        "\n",
        "    // Call the CUDA kernel\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (size + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    my_cuda_kernel<<<blocksPerGrid, threadsPerBlock>>>(input, output, size);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGfi2JOB_Dr2",
        "outputId": "d1a9c33c-3a4a-4bea-d68c-e7bc205c35ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting sumArrayGPU.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 -o sumArrayGPU.so -shared -Xcompiler -fPIC sumArrayGPU.cu"
      ],
      "metadata": {
        "id": "S-7aSCdg17iK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ctypes\n",
        "import pycuda.gpuarray as gpuarray\n",
        "import pycuda.driver as cuda\n",
        "from pycuda.compiler import SourceModule\n",
        "import pycuda.autoinit\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Load the CUDA library\n",
        "cuda_lib = ctypes.CDLL('./sumArrayGPU.so')  # Update with the correct path\n",
        "\n",
        "# Define the function prototype\n",
        "cuda_lib.my_cuda_function.argtypes = [ctypes.POINTER(ctypes.c_int), ctypes.POINTER(ctypes.c_int), ctypes.c_int]\n",
        "cuda_lib.my_cuda_function.restype = None\n",
        "\n",
        "# Prepare data\n",
        "input_data = np.array([3, 1, 33, -4]).astype(np.int32)\n",
        "output_data = np.array([0, 0, 0, 0]).astype(np.int32)\n",
        "size = len(input_data)\n",
        "\n",
        "# Use PyCUDA to allocate GPU memory\n",
        "input_gpu   = gpuarray.to_gpu(input_data)\n",
        "output_gpu  = gpuarray.to_gpu(output_data)\n",
        "\n",
        "# Call the CUDA function\n",
        "cuda_lib.my_cuda_function(ctypes.cast(input_gpu.ptr, ctypes.POINTER(ctypes.c_int)), ctypes.cast(output_gpu.ptr, ctypes.POINTER(ctypes.c_int)), size)\n",
        "\n",
        "print(input_gpu)\n",
        "print(output_gpu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peCWezQh_QUk",
        "outputId": "e9021f32-df30-4b4c-be32-f7e7eb810645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 3  1 33 -4]\n",
            "[ 6  2 66 -8]\n"
          ]
        }
      ]
    }
  ]
}