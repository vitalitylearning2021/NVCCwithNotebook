{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY18CYVTw7Zj",
        "outputId": "1a714caa-dbbe-45be-ce19-cdf9c1783c9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting sumArrayGPU.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile sumArrayGPU.cu\n",
        "// CUDA kernel function\n",
        "__global__ void my_cuda_kernel(int *input, int *output, int size) {\n",
        "    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if (tid < size) {\n",
        "        output[tid] = input[tid] * 2;  // Example: Double each element\n",
        "    }\n",
        "}\n",
        "\n",
        "// Wrapper function to call the CUDA kernel\n",
        "extern \"C\" void my_cuda_function(int *input, int *output, int size) {\n",
        "    // Allocate device memory\n",
        "    int *d_input, *d_output;\n",
        "    cudaMalloc((void**)&d_input, size * sizeof(int));\n",
        "    cudaMalloc((void**)&d_output, size * sizeof(int));\n",
        "\n",
        "    // Copy input data to device\n",
        "    cudaMemcpy(d_input, input, size * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Launch CUDA kernel\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (size + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    my_cuda_kernel<<<blocksPerGrid, threadsPerBlock>>>(d_input, d_output, size);\n",
        "\n",
        "    // Copy result back to host\n",
        "    cudaMemcpy(output, d_output, size * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output);\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 -o sumArrayGPU.so -shared -Xcompiler -fPIC sumArrayGPU.cu"
      ],
      "metadata": {
        "id": "aTU2zVbYyU6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ctypes\n",
        "\n",
        "# Load the CUDA library\n",
        "cuda_lib = ctypes.CDLL('./sumArrayGPU.so')  # Update with the correct path\n",
        "\n",
        "# Define the function prototype\n",
        "cuda_lib.my_cuda_function.argtypes = [ctypes.POINTER(ctypes.c_int), ctypes.POINTER(ctypes.c_int), ctypes.c_int]\n",
        "cuda_lib.my_cuda_function.restype = None\n",
        "\n",
        "# Prepare data\n",
        "input_data = [1, 2, 3, 4]\n",
        "output_data = [0, 0, 0, 0]\n",
        "size = len(input_data)\n",
        "\n",
        "# Convert Python lists to ctypes arrays\n",
        "input_array = (ctypes.c_int * size)(*input_data)\n",
        "output_array = (ctypes.c_int * size)(*output_data)\n",
        "\n",
        "# Call the CUDA function\n",
        "cuda_lib.my_cuda_function(input_array, output_array, size)\n",
        "\n",
        "# Print the result\n",
        "result = list(output_array)\n",
        "print(\"Result:\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Q--Pz5VzWSu",
        "outputId": "aab4ddba-4709-43f3-a9b8-851a42bd9150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: [2, 4, 6, 8]\n"
          ]
        }
      ]
    }
  ]
}